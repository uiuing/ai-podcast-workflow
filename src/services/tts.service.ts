import * as fs from 'fs';
import * as path from 'path';
import * as uuid from 'uuid';
import WebSocket from 'ws';
import { promisify } from 'util';
import ffmpeg from 'fluent-ffmpeg';
import { config } from '../config/config';
import { initializeFfmpeg } from '../config/ffmpeg.config';
import { PodcastDialogue, PodcastSpeaker } from '../types/podcast.types';
import {
  MsgType,
  ReceiveMessage,
  EventType,
  FullClientRequest,
} from '../plugins/volcengine/protocols';

// åˆå§‹åŒ– ffmpeg é…ç½®
initializeFfmpeg();

/**
 * å£°éŸ³é…ç½®æ¥å£
 */
export interface VoiceConfig {
  id: string;
  name: string;
  originalName: string;
  description: string;
  gender: 'male' | 'female';
  lang: string;
  model: string;
  note?: string;
}

/**
 * TTS WebSocket è¯·æ±‚å‚æ•°
 */
export interface TTSRequest {
  user: {
    uid: string;
  };
  req_params: {
    text: string;
    speaker: string;
    audio_params: {
      format: 'mp3' | 'ogg_opus' | 'pcm' | 'wav';
      sample_rate: 8000 | 16000 | 22050 | 24000 | 32000 | 44100 | 48000;
      speech_rate?: number;
      enable_timestamp?: boolean;
    };
    additions?: string;
  };
}

/**
 * éŸ³é¢‘ç‰‡æ®µä¿¡æ¯
 */
export interface AudioSegment {
  speaker: string;
  text: string;
  audioData: Buffer;
  duration?: number;
  timestamp?: any;
}

/**
 * éŸ³é¢‘æ ‡å‡†åŒ–é…ç½®æ¥å£
 */
interface AudioNormalizationConfig {
  normalization: {
    enabled: boolean;
    mode?: 'loudnorm' | 'compressor';
  };
  compressor?: {
    threshold: number;
    ratio: number;
    attack: number;
    release: number;
    makeup: number;
  };
  limiter?: {
    enabled: boolean;
    limit: number;
    release: number;
  };
  loudnorm: {
    I: number;
    TP: number;
    LRA: number;
  };
  processing: {
    sampleRate: number;
    tempDir: string;
    cleanupOnError: boolean;
  };
  quality?: {
    mp3?: {
      bitrate?: string;
      vbrQuality?: number;
    };
    wav?: {
      codec?: string;
    };
    ogg_opus?: {
      bitrate?: string;
    };
    useVBR?: boolean;
  };
}

/**
 * è¯­éŸ³åˆæˆæœåŠ¡
 * åŸºäºç«å±±å¼•æ“è±†åŒ…TTS WebSocket Stream API V3
 */
export class TTSService {
  private static readonly WS_ENDPOINT = config.tts.wsEndpoint;
  private static readonly APP_ID = config.tts.appId;
  private static readonly ACCESS_TOKEN = config.tts.accessToken;
  private static readonly VOICES_CONFIG_PATH = path.join(__dirname, '../config/podcast-voices.json');
  private static readonly NORMALIZATION_CONFIG_PATH = path.join(__dirname, '../config/audio-normalization.config.json');
  
  // å£°éŸ³é…ç½®ç¼“å­˜
  private static voicesCache: VoiceConfig[] | null = null;
  
  // æ ‡å‡†åŒ–é…ç½®ç¼“å­˜
  private static normalizationConfig: AudioNormalizationConfig | null = null;

  /**
   * åŠ è½½å£°éŸ³é…ç½®
   */
  private static loadVoices(): VoiceConfig[] {
    if (this.voicesCache) {
      return this.voicesCache;
    }

    try {
      const voicesData = fs.readFileSync(this.VOICES_CONFIG_PATH, 'utf-8');
      this.voicesCache = JSON.parse(voicesData) as VoiceConfig[];
      return this.voicesCache;
    } catch (error) {
      console.error('åŠ è½½å£°éŸ³é…ç½®å¤±è´¥:', error);
      return [];
    }
  }

  /**
   * åŠ è½½éŸ³é¢‘æ ‡å‡†åŒ–é…ç½®
   */
  private static loadNormalizationConfig(): AudioNormalizationConfig {
    if (this.normalizationConfig) {
      return this.normalizationConfig;
    }

    try {
      const configData = fs.readFileSync(this.NORMALIZATION_CONFIG_PATH, 'utf-8');
      this.normalizationConfig = JSON.parse(configData) as AudioNormalizationConfig;
      return this.normalizationConfig;
    } catch (error) {
      console.warn('âš ï¸  åŠ è½½éŸ³é¢‘æ ‡å‡†åŒ–é…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®:', error);
      // è¿”å›é»˜è®¤é…ç½®ï¼ˆä½¿ç”¨å‹ç¼©å™¨æ¨¡å¼ï¼‰
      return {
        normalization: {
          enabled: true,
          mode: 'compressor'
        },
        compressor: {
          threshold: -20,
          ratio: 4,
          attack: 5,
          release: 50,
          makeup: 0
        },
        limiter: {
          enabled: true,
          limit: -1.0,
          release: 5
        },
        loudnorm: {
          I: -16,
          TP: -1.5,
          LRA: 11
        },
        processing: {
          sampleRate: 24000,
          tempDir: 'temp',
          cleanupOnError: true
        }
      };
    }
  }

  /**
   * è§„èŒƒåŒ–æ–‡ä»¶è·¯å¾„ï¼ˆWindows å…¼å®¹ï¼‰
   * å°†åæ–œæ è½¬æ¢ä¸ºæ­£æ–œæ ï¼Œé¿å… ffmpeg åœ¨ Windows ä¸Šçš„è·¯å¾„é—®é¢˜
   */
  private static normalizePath(filePath: string): string {
    return filePath.replace(/\\/g, '/');
  }

  /**
   * è·å–éŸ³é¢‘å¤„ç†æ»¤é•œå­—ç¬¦ä¸²
   */
  private static getAudioFilter(): string {
    const normConfig = this.loadNormalizationConfig();
    const mode = normConfig.normalization.mode || 'compressor';

    if (mode === 'loudnorm') {
      // ä½¿ç”¨ loudnorm å®Œå…¨æ ‡å‡†åŒ–
      const { I, TP, LRA } = normConfig.loudnorm;
      return `loudnorm=I=${I}:TP=${TP}:LRA=${LRA}`;
    } else {
      // ä½¿ç”¨å‹ç¼©å™¨æ¨¡å¼ï¼šä»…é™åˆ¶å³°å€¼ï¼Œä¿æŒåŠ¨æ€èŒƒå›´
      const filters: string[] = [];
      
      if (normConfig.compressor) {
        const { threshold, ratio, attack, release, makeup } = normConfig.compressor;
        // acompressor: åŠ¨æ€èŒƒå›´å‹ç¼©ï¼Œé™ä½è¿‡å¤§çš„å£°éŸ³
        filters.push(
          `acompressor=threshold=${threshold}dB:ratio=${ratio}:attack=${attack}:release=${release}:makeup=${makeup}`
        );
      }
      
      if (normConfig.limiter?.enabled) {
        const { limit, release } = normConfig.limiter;
        // alimiter: ç¡¬é™åˆ¶å³°å€¼ï¼Œé˜²æ­¢å‰Šæ³¢
        filters.push(`alimiter=limit=${limit}:release=${release}`);
      }
      
      return filters.join(',');
    }
  }

  /**
   * æ ¹æ®å£°éŸ³åå­—è·å–å£°éŸ³é…ç½®
   * @param speakerName å£°éŸ³åå­—ï¼ˆå¦‚"è¯­å«£"ï¼‰æˆ–å£°éŸ³IDï¼ˆå¦‚"zh_female_vv_uranus_bigtts"ï¼‰
   * @returns å£°éŸ³é…ç½®ï¼Œå¦‚æœæ‰¾ä¸åˆ°è¿”å› undefined
   */
  private static getVoiceConfig(speakerName: string): VoiceConfig | undefined {
    const voices = this.loadVoices();
    
    // å…ˆæŒ‰åå­—æŸ¥æ‰¾
    let voice = voices.find(v => v.name === speakerName);
    
    // å¦‚æœæ‰¾ä¸åˆ°ï¼Œå†æŒ‰IDæŸ¥æ‰¾
    if (!voice) {
      voice = voices.find(v => v.id === speakerName);
    }
    
    return voice;
  }

  /**
   * è·å–å£°éŸ³çš„APIè°ƒç”¨å‚æ•°
   * @param speakerName å£°éŸ³åå­—æˆ–ID
   * @returns { voiceId: å£°éŸ³ID, resourceId: èµ„æºID(model) }
   */
  private static getVoiceParams(speakerName: string): { voiceId: string; resourceId: string } {
    const voice = this.getVoiceConfig(speakerName);
    
    if (voice) {
      return {
        voiceId: voice.id,
        resourceId: voice.model  // ç›´æ¥ä½¿ç”¨é…ç½®ä¸­çš„ model å­—æ®µä½œä¸º resourceId
      };
    }
    
    // å¦‚æœæ‰¾ä¸åˆ°é…ç½®ï¼Œä½¿ç”¨ä¼ å…¥çš„åå­—ä½œä¸ºIDï¼Œå¹¶ä½¿ç”¨é»˜è®¤èµ„æºID
    console.warn(`âš ï¸  æœªæ‰¾åˆ°å£°éŸ³é…ç½®: ${speakerName}ï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®`);
    return {
      voiceId: speakerName,
      resourceId: 'seed-tts-2.0'  // é»˜è®¤èµ„æºID
    };
  }

  /**
   * ç”Ÿæˆå•å¥è¯­éŸ³ - ä½¿ç”¨ WebSocket Stream API
   */
  static async synthesizeSingle(
    text: string,
    speaker: string,
    taskId?: number,
    options?: {
      format?: 'mp3' | 'ogg_opus' | 'pcm' | 'wav';
      sampleRate?: number;
      speechRate?: number;
      enableTimestamp?: boolean;
    }
  ): Promise<AudioSegment> {
    const startTime = Date.now();
    let requestBody: TTSRequest | null = null;
    let ws: WebSocket | null = null;

    try {
      // è·å–å£°éŸ³ID
      // è·å–å£°éŸ³å‚æ•°ï¼ˆIDå’Œèµ„æºIDï¼‰
      const { voiceId, resourceId } = this.getVoiceParams(speaker);
      
      console.log(`ğŸ™ï¸ [TTS] å¼€å§‹åˆæˆ - TaskId: ${taskId || 'N/A'}, Speaker: ${speaker}, æ–‡æœ¬: ${text.length}å­—`);
      
      if (!this.APP_ID) {
        throw new Error('TTS_APP_ID æœªé…ç½®ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡');
      }
      if (!this.ACCESS_TOKEN) {
        throw new Error('TTS_ACCESS_TOKEN æœªé…ç½®ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡');
      }

      // åˆ›å»º WebSocket è¿æ¥
      const connectId = uuid.v4();
      const headers = {
        'X-Api-App-Key': this.APP_ID,
        'X-Api-Access-Key': this.ACCESS_TOKEN,
        'X-Api-Resource-Id': resourceId,
        'X-Api-Connect-Id': connectId,
      };


      ws = new WebSocket(this.WS_ENDPOINT, {
        headers,
        skipUTF8Validation: true,
      });

      // å¤„ç†è¿æ¥é”™è¯¯
      ws.on('unexpected-response', (request, response) => {
        console.error(`\nâŒ æ”¶åˆ°æ„å¤–çš„ HTTP å“åº”:`);
        console.error(`   - çŠ¶æ€ç : ${response.statusCode} ${response.statusMessage}`);
        console.error(`   - å“åº”å¤´:`, JSON.stringify(response.headers, null, 2));
        
        let body = '';
        response.on('data', (chunk) => {
          body += chunk.toString();
        });
        response.on('end', () => {
          console.error(`   - å“åº”ä½“:`, body);
          console.error(`\nğŸ’¡ å¸¸è§ 403 é”™è¯¯åŸå› :`);
          console.error(`   1. ACCESS_TOKEN å·²è¿‡æœŸ - è¯·åˆ°ç«å±±å¼•æ“æ§åˆ¶å°é‡æ–°ç”Ÿæˆ`);
          console.error(`   2. APP_ID é…ç½®é”™è¯¯ - è¯·æ£€æŸ¥æ˜¯å¦å¯¹åº”æ­£ç¡®çš„åº”ç”¨`);
          console.error(`   3. Resource-Id ä¸åŒ¹é… - å½“å‰ä½¿ç”¨: ${resourceId}`);
          console.error(`   4. IP ç™½åå•é™åˆ¶ - è¯·æ£€æŸ¥ç«å±±å¼•æ“æ§åˆ¶å°çš„ IP ç™½åå•è®¾ç½®`);
          console.error(`   5. è´¦å·æ¬ è´¹æˆ–æƒé™ä¸è¶³`);
        });
      });

      // ç­‰å¾…è¿æ¥å»ºç«‹
      await new Promise((resolve, reject) => {
        const timeout = setTimeout(() => {
          reject(new Error('WebSocket è¿æ¥è¶…æ—¶ï¼ˆ10ç§’ï¼‰'));
        }, 10000);

        ws!.on('open', () => {
          clearTimeout(timeout);
          resolve(undefined);
        });
        
        ws!.on('error', (error) => {
          clearTimeout(timeout);
          reject(error);
        });
      });

      // æ„å»ºè¯·æ±‚å‚æ•°
      const sampleRate = options?.sampleRate || 24000;
      const format = options?.format || 'wav';
      requestBody = {
        user: {
          uid: taskId?.toString() || uuid.v4(),
        },
        req_params: {
          text,
          speaker: voiceId,
          audio_params: {
            format: format,
            sample_rate: sampleRate as 8000 | 16000 | 22050 | 24000 | 32000 | 44100 | 48000,
            speech_rate: options?.speechRate || 0,
            enable_timestamp: options?.enableTimestamp || false,
          },
          additions: JSON.stringify({
            disable_markdown_filter: false,
          }),
        },
      };

      // å‘é€è¯·æ±‚
      await FullClientRequest(
        ws,
        new TextEncoder().encode(JSON.stringify(requestBody))
      );

      // æ¥æ”¶éŸ³é¢‘æ•°æ®
      const audioChunks: Uint8Array[] = [];
      let timestampData: any = null;

      while (true) {
        const msg = await ReceiveMessage(ws);

        switch (msg.type) {
          case MsgType.FullServerResponse:
            // æ£€æŸ¥é”™è¯¯ä¿¡æ¯
            if (msg.payload && msg.payload.length > 0) {
              try {
                const responseData = JSON.parse(new TextDecoder().decode(msg.payload));
                if (responseData.code && responseData.code !== 0) {
                  console.error(`âŒ TTSæœåŠ¡å™¨é”™è¯¯: code=${responseData.code}, message=${responseData.message}`);
                }
              } catch (e) {
                // å¯èƒ½ä¸æ˜¯JSONæ ¼å¼
              }
            }
            break;
          case MsgType.AudioOnlyServer:
            audioChunks.push(msg.payload);
            break;
          default:
            throw new Error(`æœªçŸ¥æ¶ˆæ¯ç±»å‹: ${msg.toString()}`);
        }

        if (
          msg.type === MsgType.FullServerResponse &&
          msg.event === EventType.SessionFinished
        ) {
          break;
        }
      }

      if (audioChunks.length === 0) {
        throw new Error('æœªæ”¶åˆ°éŸ³é¢‘æ•°æ®');
      }

      // åˆå¹¶éŸ³é¢‘æ•°æ®
      const audioData = Buffer.concat(audioChunks);
      const responseTime = Date.now() - startTime;

      console.log(`âœ… [TTS] åˆæˆå®Œæˆ - ${responseTime}ms, ${(audioData.length / 1024).toFixed(2)}KB`);

      // å…³é—­ WebSocket
      ws.close();

      return {
        speaker,
        text,
        audioData,
        timestamp: timestampData
      };

    } catch (error: any) {
      const responseTime = Date.now() - startTime;

      console.error(`âŒ [TTS] åˆæˆå¤±è´¥ - ${error.message}`);

      // ç¡®ä¿å…³é—­ WebSocket
      if (ws) {
        try {
          ws.close();
        } catch (closeError) {
          // å¿½ç•¥å…³é—­é”™è¯¯
        }
      }

      throw new Error(`è¯­éŸ³åˆæˆå¤±è´¥: ${error.message}`);
    }
  }

  /**
   * æ‰¹é‡åˆæˆæ’­å®¢å¯¹è¯
   */
  static async synthesizeDialogue(
    dialogue: PodcastDialogue[],
    taskId?: number,
    options?: {
      format?: 'mp3' | 'ogg_opus' | 'pcm' | 'wav';
      sampleRate?: number;
      speechRate?: number;
      enableTimestamp?: boolean;
      onProgress?: (current: number, total: number) => void;
    }
  ): Promise<AudioSegment[]> {
    console.log(`ğŸ™ï¸ å¼€å§‹æ‰¹é‡åˆæˆ ${dialogue.length} æ®µå¯¹è¯`);

    const segments: AudioSegment[] = [];
    const total = dialogue.length;

    for (let i = 0; i < dialogue.length; i++) {
      const item = dialogue[i];
      
      try {
        const segment = await this.synthesizeSingle(
          item.text,
          item.speaker,
          taskId,
          options
        );

        segments.push(segment);

        // è¿›åº¦å›è°ƒ
        if (options?.onProgress) {
          options.onProgress(i + 1, total);
        }

        // é¿å…è¯·æ±‚è¿‡å¿«ï¼Œæ·»åŠ çŸ­æš‚å»¶è¿Ÿ
        if (i < dialogue.length - 1) {
          await this.delay(100);
        }

      } catch (error: any) {
        throw new Error(`ç¬¬ ${i + 1} æ®µå¯¹è¯åˆæˆå¤±è´¥: ${error.message}`);
      }
    }

    console.log(`âœ… æ‰¹é‡åˆæˆå®Œæˆ: ${segments.length}/${total} æ®µ`);

    return segments;
  }

  /**
   * æ£€æŸ¥ ffmpeg æ˜¯å¦å¯ç”¨
   */
  private static async checkFfmpegAvailable(): Promise<boolean> {
    return new Promise((resolve) => {
      ffmpeg.getAvailableFormats((err, formats) => {
        if (err) {
          resolve(false);
        } else {
          resolve(true);
        }
      });
    });
  }

  /**
   * ä½¿ç”¨ ffmpeg æ ‡å‡†åŒ–å•ä¸ªéŸ³é¢‘ç‰‡æ®µçš„éŸ³é‡
   * @param audioData éŸ³é¢‘æ•°æ®
   * @param format éŸ³é¢‘æ ¼å¼
   * @returns æ ‡å‡†åŒ–åçš„éŸ³é¢‘æ•°æ®
   */
  private static async normalizeAudioVolume(
    audioData: Buffer,
    format: 'mp3' | 'ogg_opus' | 'pcm' | 'wav'
  ): Promise<Buffer> {
    const normConfig = this.loadNormalizationConfig();
    const tempDir = path.join(process.cwd(), normConfig.processing.tempDir);
    
    if (!fs.existsSync(tempDir)) {
      fs.mkdirSync(tempDir, { recursive: true });
    }

    const inputFile = path.join(tempDir, `temp_input_${uuid.v4()}.${format}`);
    const outputFile = path.join(tempDir, `temp_output_${uuid.v4()}.${format}`);

    try {
      // å†™å…¥ä¸´æ—¶è¾“å…¥æ–‡ä»¶
      fs.writeFileSync(inputFile, audioData);

      // ä½¿ç”¨ ffmpeg loudnorm æ»¤é•œæ ‡å‡†åŒ–éŸ³é‡
      // loudnorm æ˜¯ä¸“ä¸šçš„éŸ³é‡æ ‡å‡†åŒ–æ»¤é•œï¼Œç¬¦åˆ EBU R128 æ ‡å‡†
      const { I, TP, LRA } = normConfig.loudnorm;
      const sampleRate = normConfig.processing.sampleRate;
      const qualityOptions = this.getQualityOptions(format);
      
      await new Promise<void>((resolve, reject) => {
        const command = ffmpeg(this.normalizePath(inputFile))
          .audioFilters(`loudnorm=I=${I}:TP=${TP}:LRA=${LRA}`)
          .audioFrequency(sampleRate);
        
        // æ·»åŠ éŸ³é¢‘è´¨é‡å‚æ•°
        if (qualityOptions.length > 0) {
          command.outputOptions(qualityOptions);
        }
        
        // æ·»åŠ æ›´å¤§çš„è¾“å‡ºç¼“å†²åŒºé™åˆ¶ï¼ˆé˜²æ­¢"Result too large"é”™è¯¯ï¼‰
        command.outputOptions([
          '-max_muxing_queue_size', '9999',
          '-bufsize', '10M'
        ]);
        
        command
          .save(this.normalizePath(outputFile))
          .on('end', () => resolve())
          .on('error', (err) => reject(err));
      });

      // è¯»å–æ ‡å‡†åŒ–åçš„éŸ³é¢‘
      const normalizedAudio = fs.readFileSync(outputFile);

      // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
      fs.unlinkSync(inputFile);
      fs.unlinkSync(outputFile);

      return normalizedAudio;
    } catch (error: any) {
      // æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆæ ¹æ®é…ç½®ï¼‰
      if (normConfig.processing.cleanupOnError) {
        if (fs.existsSync(inputFile)) {
          fs.unlinkSync(inputFile);
        }
        if (fs.existsSync(outputFile)) {
          fs.unlinkSync(outputFile);
        }
      }
      throw new Error(`éŸ³é‡æ ‡å‡†åŒ–å¤±è´¥: ${error.message}`);
    }
  }

  /**
   * ç”Ÿæˆé™éŸ³éŸ³é¢‘æ–‡ä»¶
   * @param duration é™éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰
   * @param sampleRate é‡‡æ ·ç‡
   * @param format éŸ³é¢‘æ ¼å¼
   * @returns é™éŸ³éŸ³é¢‘æ–‡ä»¶è·¯å¾„
   */
  private static async generateSilence(
    duration: number,
    sampleRate: number,
    format: 'mp3' | 'ogg_opus' | 'pcm' | 'wav',
    tempDir: string
  ): Promise<string> {
    const silenceFile = path.join(tempDir, `silence_${duration}s_${uuid.v4()}.${format}`);
    const tempPcmFile = path.join(tempDir, `silence_temp_${uuid.v4()}.pcm`);
    
    try {
      // æ–¹æ³•1: å…ˆç”Ÿæˆ PCM é™éŸ³æ•°æ®ï¼Œå†è½¬æ¢ä¸ºç›®æ ‡æ ¼å¼
      // è¿™æ¯” lavfi è™šæ‹Ÿè¾“å…¥æ›´å…¼å®¹å„ç§ ffmpeg ç‰ˆæœ¬
      
      // ç”Ÿæˆçº¯é™éŸ³çš„ PCM æ•°æ® (16-bit, mono)
      const numSamples = Math.floor(duration * sampleRate);
      const silenceBuffer = Buffer.alloc(numSamples * 2); // 16-bit = 2 bytes per sample
      // Buffer.alloc é»˜è®¤å¡«å…… 0ï¼Œä»£è¡¨é™éŸ³
      
      // å†™å…¥ä¸´æ—¶ PCM æ–‡ä»¶
      fs.writeFileSync(tempPcmFile, silenceBuffer);
      
      // ä½¿ç”¨ ffmpeg å°† PCM è½¬æ¢ä¸ºç›®æ ‡æ ¼å¼
      await new Promise<void>((resolve, reject) => {
        ffmpeg()
          .input(this.normalizePath(tempPcmFile))
          .inputFormat('s16le') // 16-bit signed little-endian PCM
          .inputOptions([
            `-ar ${sampleRate}`,  // é‡‡æ ·ç‡
            '-ac 1'                // å•å£°é“
          ])
          .audioCodec(this.getAudioCodec(format))
          .save(this.normalizePath(silenceFile))
          .on('end', () => resolve())
          .on('error', (err) => reject(err));
      });
      
      // æ¸…ç†ä¸´æ—¶ PCM æ–‡ä»¶
      if (fs.existsSync(tempPcmFile)) {
        fs.unlinkSync(tempPcmFile);
      }
      
      return silenceFile;
    } catch (error: any) {
      // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
      if (fs.existsSync(tempPcmFile)) {
        try {
          fs.unlinkSync(tempPcmFile);
        } catch (e) {}
      }
      throw new Error(`ç”Ÿæˆé™éŸ³å¤±è´¥: ${error.message}`);
    }
  }

  /**
   * æ ¹æ®æ ¼å¼è·å–éŸ³é¢‘ç¼–ç å™¨
   */
  private static getAudioCodec(format: 'mp3' | 'ogg_opus' | 'pcm' | 'wav'): string {
    switch (format) {
      case 'mp3':
        return 'libmp3lame';
      case 'ogg_opus':
        return 'libopus';
      case 'wav':
        return 'pcm_s16le';
      case 'pcm':
        return 'pcm_s16le';
      default:
        return 'libmp3lame';
    }
  }

  /**
   * è·å–éŸ³é¢‘è´¨é‡ç¼–ç å‚æ•°
   */
  private static getQualityOptions(format: 'mp3' | 'ogg_opus' | 'pcm' | 'wav'): string[] {
    const normConfig = this.loadNormalizationConfig();
    const quality = normConfig.quality;
    
    if (!quality) {
      // å¦‚æœæ²¡æœ‰é…ç½®ï¼Œä½¿ç”¨é»˜è®¤é«˜è´¨é‡å‚æ•°
      return format === 'mp3' ? ['-q:a 0'] : ['-b:a 320k'];
    }

    const options: string[] = [];
    
    switch (format) {
      case 'mp3':
        if (quality.useVBR && quality.mp3?.vbrQuality !== undefined) {
          // VBR æ¨¡å¼ï¼ˆè´¨é‡ä¼˜å…ˆï¼‰
          options.push(`-q:a ${quality.mp3.vbrQuality}`);
          console.log(`   ä½¿ç”¨ MP3 VBR ç¼–ç ï¼Œè´¨é‡ç­‰çº§: ${quality.mp3.vbrQuality} (0=æœ€é«˜è´¨é‡)`);
        } else if (quality.mp3?.bitrate) {
          // CBR æ¨¡å¼ï¼ˆå›ºå®šæ¯”ç‰¹ç‡ï¼‰
          options.push(`-b:a ${quality.mp3.bitrate}`);
          console.log(`   ä½¿ç”¨ MP3 CBR ç¼–ç ï¼Œæ¯”ç‰¹ç‡: ${quality.mp3.bitrate}`);
        } else {
          options.push('-q:a 0'); // é»˜è®¤æœ€é«˜è´¨é‡ VBR
        }
        break;
      
      case 'wav':
        // WAV æ ¼å¼ï¼Œä¿æŒ PCM ç¼–ç 
        if (quality.wav?.codec) {
          options.push(`-acodec ${quality.wav.codec}`);
        }
        break;
      
      case 'ogg_opus':
        if (quality.ogg_opus?.bitrate) {
          options.push(`-b:a ${quality.ogg_opus.bitrate}`);
          console.log(`   ä½¿ç”¨ Opus ç¼–ç ï¼Œæ¯”ç‰¹ç‡: ${quality.ogg_opus.bitrate}`);
        } else {
          options.push('-b:a 256k'); // é»˜è®¤é«˜è´¨é‡
        }
        break;
      
      default:
        options.push('-b:a 320k');
    }
    
    return options;
  }

  /**
   * ä½¿ç”¨ ffmpeg concat åˆå¹¶å¤šä¸ªéŸ³é¢‘æ–‡ä»¶ï¼ˆä»…åˆå¹¶ï¼Œä¸åšéŸ³é‡æ ‡å‡†åŒ–ï¼‰
   * @param segments éŸ³é¢‘ç‰‡æ®µæ•°ç»„ï¼ˆåŒ…å«pauseä¿¡æ¯ï¼‰
   * @param dialogue åŸå§‹å¯¹è¯æ•°æ®ï¼ˆåŒ…å«AIåˆ¤æ–­çš„åœé¡¿æ—¶é•¿ï¼‰
   * @param format éŸ³é¢‘æ ¼å¼
   * @returns åˆå¹¶åçš„éŸ³é¢‘ï¼ˆæœªæ ‡å‡†åŒ–ï¼‰
   */
  private static async mergeWithFfmpeg(
    segments: AudioSegment[],
    dialogue: PodcastDialogue[],
    format: 'mp3' | 'ogg_opus' | 'pcm' | 'wav'
  ): Promise<Buffer> {
    const normConfig = this.loadNormalizationConfig();
    const tempDir = path.join(process.cwd(), normConfig.processing.tempDir);
    
    if (!fs.existsSync(tempDir)) {
      fs.mkdirSync(tempDir, { recursive: true });
    }
    
    // ç¡®ä¿ä¸´æ—¶ç›®å½•æœ‰å†™æƒé™ï¼ˆWindowsç‰¹æ®Šå¤„ç†ï¼‰
    try {
      const testFile = path.join(tempDir, `test_${Date.now()}.txt`);
      fs.writeFileSync(testFile, 'test');
      fs.unlinkSync(testFile);
    } catch (err: any) {
      console.error(`âš ï¸  ä¸´æ—¶ç›®å½•æ— å†™æƒé™: ${tempDir}`);
      throw new Error(`ä¸´æ—¶ç›®å½•æ— å†™æƒé™: ${err.message}`);
    }

    const tempFiles: string[] = [];
    const concatListFile = path.join(tempDir, `concat_list_${uuid.v4()}.txt`);
    const mergedFile = path.join(tempDir, `merged_temp_${uuid.v4()}.${format}`);

    try {
      // 1. ç”Ÿæˆæ‰€æœ‰éœ€è¦çš„é™éŸ³æ–‡ä»¶ï¼ˆæ ¹æ®AIåˆ¤æ–­çš„åœé¡¿æ—¶é•¿ï¼‰
      console.log(`ğŸ”‡ ç”Ÿæˆæ™ºèƒ½é™éŸ³ç‰‡æ®µï¼ˆAIåˆ¤æ–­ï¼‰...`);
      const sampleRate = normConfig.processing.sampleRate;
      
      // å¼€å¤´é™éŸ³ï¼šå›ºå®š1.0ç§’
      const openingSilence = await this.generateSilence(1.0, sampleRate, format, tempDir);
      tempFiles.push(openingSilence);
      
      // ä¸ºæ¯æ®µå¯¹è¯ç”Ÿæˆå¯¹åº”çš„åœé¡¿é™éŸ³
      const pauseSilences: string[] = [];
      for (let i = 0; i < dialogue.length; i++) {
        // è·å–AIåˆ¤æ–­çš„åœé¡¿æ—¶é•¿ï¼Œé»˜è®¤0.3ç§’
        const pauseDuration = dialogue[i].pause_after || 0.3;
        
        // åªä¸ºéæœ€åä¸€ä¸ªç‰‡æ®µç”Ÿæˆåœé¡¿
        if (i < dialogue.length - 1) {
          const pauseFile = await this.generateSilence(pauseDuration, sampleRate, format, tempDir);
          pauseSilences.push(pauseFile);
          tempFiles.push(pauseFile);
        }
      }

      console.log(`   ç”Ÿæˆå¼€å¤´é™éŸ³: 1.0ç§’`);
      console.log(`   ç”Ÿæˆ ${pauseSilences.length} ä¸ªæ™ºèƒ½åœé¡¿ï¼ˆAIåˆ¤æ–­æ—¶é•¿ï¼‰`);

      // 2. å°†éŸ³é¢‘ç‰‡æ®µå†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼Œå¹¶æ„å»ºåŒ…å«æ™ºèƒ½é™éŸ³çš„concatåˆ—è¡¨
      console.log(`ğŸ“ å‡†å¤‡åˆå¹¶æ–‡ä»¶åˆ—è¡¨ï¼ˆå«AIæ™ºèƒ½åœé¡¿ï¼‰...`);
      const concatList: string[] = [];
      
      // æ·»åŠ å¼€å¤´çš„1ç§’é™éŸ³
      concatList.push(`file '${this.normalizePath(openingSilence)}'`);
      
      for (let i = 0; i < segments.length; i++) {
        // æ·»åŠ éŸ³é¢‘ç‰‡æ®µ
        const tempFile = path.join(tempDir, `segment_${uuid.v4()}.${format}`);
        fs.writeFileSync(tempFile, segments[i].audioData);
        tempFiles.push(tempFile);
        concatList.push(`file '${this.normalizePath(tempFile)}'`);
        
        // åœ¨æ¯ä¸ªç‰‡æ®µåæ·»åŠ AIåˆ¤æ–­çš„åœé¡¿ï¼ˆæœ€åä¸€ä¸ªç‰‡æ®µé™¤å¤–ï¼‰
        if (i < segments.length - 1) {
          const pauseDuration = dialogue[i].pause_after || 0.8;
          concatList.push(`file '${this.normalizePath(pauseSilences[i])}'`);
          console.log(`   ç‰‡æ®µ${i + 1}ååœé¡¿: ${pauseDuration.toFixed(1)}ç§’`);
        }
      }

      console.log(`   æ·»åŠ å¼€å¤´é™éŸ³: 1.0ç§’`);

      // 3. åˆ›å»º ffmpeg concat åˆ—è¡¨æ–‡ä»¶
      fs.writeFileSync(concatListFile, concatList.join('\n'));

      // 4. ä½¿ç”¨ ffmpeg concat åè®®åˆå¹¶éŸ³é¢‘
      // -f concat: ä½¿ç”¨ concat åˆ†ç¦»å™¨
      // -safe 0: å…è®¸ä½¿ç”¨ç»å¯¹è·¯å¾„
      // -c copy: ç›´æ¥å¤åˆ¶æµï¼Œä¸é‡æ–°ç¼–ç ï¼ˆå¿«é€Ÿï¼‰
      console.log(`ğŸ”— åˆå¹¶éŸ³é¢‘ç‰‡æ®µï¼ˆå«é™éŸ³ï¼‰...`);
      
      await new Promise<void>((resolve, reject) => {
        ffmpeg()
          .input(this.normalizePath(concatListFile))
          .inputOptions(['-f concat', '-safe 0'])
          .outputOptions('-c copy')
          .save(this.normalizePath(mergedFile))
          .on('end', () => resolve())
          .on('error', (err) => reject(err));
      });

      console.log(`âœ… éŸ³é¢‘åˆå¹¶å®Œæˆ`);

      // è¯»å–åˆå¹¶åçš„éŸ³é¢‘ï¼ˆä¸åšéŸ³é‡æ ‡å‡†åŒ–ï¼‰
      const mergedAudio = fs.readFileSync(mergedFile);

      // æ¸…ç†æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶
      tempFiles.forEach(file => {
        if (fs.existsSync(file)) {
          fs.unlinkSync(file);
        }
      });
      if (fs.existsSync(concatListFile)) {
        fs.unlinkSync(concatListFile);
      }
      if (fs.existsSync(mergedFile)) {
        fs.unlinkSync(mergedFile);
      }

      console.log(`âœ… éŸ³é¢‘åˆå¹¶å®Œæˆï¼ˆåˆå¹¶ + AIæ™ºèƒ½é™éŸ³é—´éš”ï¼‰: ${(mergedAudio.length / 1024 / 1024).toFixed(2)} MB`);

      return mergedAudio;
    } catch (error: any) {
      // æ¸…ç†æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶
      tempFiles.forEach(file => {
        if (fs.existsSync(file)) {
          try {
            fs.unlinkSync(file);
          } catch (e) {}
        }
      });
      if (fs.existsSync(concatListFile)) {
        try {
          fs.unlinkSync(concatListFile);
        } catch (e) {}
      }
      if (fs.existsSync(mergedFile)) {
        try {
          fs.unlinkSync(mergedFile);
        } catch (e) {}
      }
      throw new Error(`ä½¿ç”¨ ffmpeg åˆå¹¶éŸ³é¢‘å¤±è´¥: ${error.message}`);
    }
  }

  /**
   * åˆå¹¶å¤šä¸ªéŸ³é¢‘ç‰‡æ®µä¸ºå®Œæ•´éŸ³é¢‘ï¼ˆå«AIæ™ºèƒ½é™éŸ³é—´éš”ï¼Œä¸å«éŸ³é‡æ ‡å‡†åŒ–ï¼‰
   * æ³¨æ„ï¼šéŸ³é‡æ ‡å‡†åŒ–åº”è¯¥åœ¨æ‰€æœ‰å†…å®¹ï¼ˆåŒ…æ‹¬BGMï¼‰å¤„ç†å®Œæˆåæœ€åè¿›è¡Œ
   */
  static async mergeAudioSegments(
    segments: AudioSegment[],
    dialogue: PodcastDialogue[],
    format: 'mp3' | 'ogg_opus' | 'pcm' | 'wav' = 'mp3'
  ): Promise<Buffer> {
    // æ£€æŸ¥ ffmpeg æ˜¯å¦å¯ç”¨
    const hasFfmpeg = await this.checkFfmpegAvailable();
    
    if (hasFfmpeg) {
      console.log(`ğŸšï¸  ä½¿ç”¨ ffmpeg åˆå¹¶éŸ³é¢‘ï¼ˆAIæ™ºèƒ½é™éŸ³é—´éš”ï¼‰...`);
      console.log(`   æ™ºèƒ½åœé¡¿: AIæ ¹æ®å¯¹è¯å†…å®¹åŠ¨æ€åˆ¤æ–­ï¼ˆ0.3-2.0ç§’ï¼‰`);
      console.log(`   ğŸ’¡ éŸ³é‡æ ‡å‡†åŒ–å°†åœ¨æ‰€æœ‰å†…å®¹å¤„ç†å®Œæˆåæœ€åè¿›è¡Œ`);
      
      try {
        return await this.mergeWithFfmpeg(segments, dialogue, format);
      } catch (error: any) {
        console.warn(`âš ï¸  ffmpeg åˆå¹¶å¤±è´¥ï¼Œé™çº§åˆ°ç®€å•æ‹¼æ¥: ${error.message}`);
        console.warn(`   âš ï¸  ç®€å•æ‹¼æ¥æ¨¡å¼ä¸æ”¯æŒé™éŸ³é—´éš”`);
        // é™çº§åˆ°ç®€å•æ‹¼æ¥
        const audioBuffers = segments.map(seg => seg.audioData);
        const mergedAudio = Buffer.concat(audioBuffers);
        console.log(`âœ… éŸ³é¢‘åˆå¹¶å®Œæˆï¼ˆç®€å•æ‹¼æ¥ï¼‰: ${(mergedAudio.length / 1024 / 1024).toFixed(2)} MB`);
        return mergedAudio;
      }
    } else {
      console.warn(`âš ï¸  æœªæ£€æµ‹åˆ° ffmpegï¼Œä½¿ç”¨ç®€å•æ‹¼æ¥ï¼ˆä¸å«é™éŸ³é—´éš”ï¼‰`);
      console.warn(`   ğŸ’¡ å»ºè®®å®‰è£… ffmpeg ä»¥è·å¾—AIæ™ºèƒ½é™éŸ³é—´éš”åŠŸèƒ½`);
      // å¯¹äºPCMå’ŒWAVæ ¼å¼ï¼Œå¯ä»¥ç›´æ¥æ‹¼æ¥
      // å¯¹äºMP3å’ŒOGG_OPUSï¼Œç®€å•æ‹¼æ¥å¯èƒ½æœ‰é—®é¢˜ï¼Œä½†é€šå¸¸ä¹Ÿèƒ½æ’­æ”¾
      const audioBuffers = segments.map(seg => seg.audioData);
      const mergedAudio = Buffer.concat(audioBuffers);
      console.log(`âœ… éŸ³é¢‘åˆå¹¶å®Œæˆï¼ˆç®€å•æ‹¼æ¥ï¼‰: ${(mergedAudio.length / 1024 / 1024).toFixed(2)} MB`);
      return mergedAudio;
    }
  }

  /**
   * å¯¹æœ€ç»ˆéŸ³é¢‘è¿›è¡ŒéŸ³é‡æ ‡å‡†åŒ–å¤„ç†ï¼ˆç®€åŒ–æ–¹æ¡ˆï¼šä½¿ç”¨ loudnorm é€šç”¨æ ‡å‡†åŒ–ï¼Œä¿æŒåŠ¨æ€èŒƒå›´ï¼‰
   * @param audioBuffer å¾…å¤„ç†çš„éŸ³é¢‘Buffer
   * @param format éŸ³é¢‘æ ¼å¼
   * @returns æ ‡å‡†åŒ–åçš„éŸ³é¢‘Buffer
   */
  static async normalizeAudioFinal(
    audioBuffer: Buffer,
    format: 'mp3' | 'ogg_opus' | 'pcm' | 'wav'
  ): Promise<Buffer> {
    const normConfig = this.loadNormalizationConfig();
    
    // æ£€æŸ¥æ˜¯å¦å¯ç”¨éŸ³é‡æ ‡å‡†åŒ–
    if (!normConfig.normalization.enabled) {
      console.log(`â„¹ï¸  éŸ³é‡æ ‡å‡†åŒ–å·²ç¦ç”¨ï¼ˆé…ç½®æ–‡ä»¶è®¾ç½®ï¼‰ï¼Œè·³è¿‡å¤„ç†`);
      return audioBuffer;
    }
    
    // ä½¿ç”¨ç³»ç»Ÿä¸´æ—¶ç›®å½•ï¼ˆè·¯å¾„æ›´çŸ­ï¼Œé¿å…Windowsè·¯å¾„é—®é¢˜ï¼‰
    const os = require('os');
    const tempDir = os.tmpdir();
    const timestamp = Date.now();
    const inputFile = path.join(tempDir, `in_${timestamp}.${format}`);
    const outputFile = path.join(tempDir, `out_${timestamp}.${format}`);
    
    try {
      // å†™å…¥è¾“å…¥æ–‡ä»¶
      fs.writeFileSync(inputFile, audioBuffer);
      
      const { I, TP, LRA } = normConfig.loudnorm;
      
      console.log(`ğŸ”Š éŸ³é‡æ ‡å‡†åŒ–å¤„ç†ï¼ˆloudnorm - ä¿æŒåŠ¨æ€èŒƒå›´ï¼‰...`);
      console.log(`   ç›®æ ‡å“åº¦: ${I} LUFSï¼ˆç¬¦åˆæ’­å®¢æ ‡å‡†ï¼‰`);
      console.log(`   çœŸå³°å€¼é™åˆ¶: ${TP} dBFS`);
      console.log(`   åŠ¨æ€èŒƒå›´: ${LRA} LU`);
      
      // ä½¿ç”¨ loudnorm æ»¤é•œ - ç®€å•ã€é€šç”¨ã€æ•ˆæœå¥½
      const loudnormFilter = `loudnorm=I=${I}:TP=${TP}:LRA=${LRA}`;
      
      await new Promise<void>((resolve, reject) => {
        ffmpeg(inputFile)
          .audioFilters(loudnormFilter)
          .audioCodec(this.getAudioCodec(format))
          .audioBitrate('256k')  // ä½¿ç”¨å›ºå®šæ¯”ç‰¹ç‡ï¼Œç®€å•ç¨³å®š
          .save(outputFile)
          .on('start', (cmdLine) => {
            console.log(`   å¤„ç†ä¸­...`);
          })
          .on('end', () => {
            resolve();
          })
          .on('error', (err) => {
            reject(err);
          });
      });
      
      // è¯»å–æ ‡å‡†åŒ–åçš„éŸ³é¢‘
      const normalizedAudio = fs.readFileSync(outputFile);
      
      console.log(`âœ… éŸ³é‡æ ‡å‡†åŒ–å®Œæˆ: ${(normalizedAudio.length / 1024 / 1024).toFixed(2)} MB`);
      
      // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
      try {
        fs.unlinkSync(inputFile);
        fs.unlinkSync(outputFile);
      } catch (e) {
        // å¿½ç•¥æ¸…ç†é”™è¯¯
      }
      
      return normalizedAudio;
      
    } catch (error: any) {
      console.error(`âŒ éŸ³é‡æ ‡å‡†åŒ–å¤±è´¥: ${error.message}`);
      console.warn(`   âš ï¸  ä½¿ç”¨åŸå§‹éŸ³é¢‘ï¼ˆæ— æ ‡å‡†åŒ–ï¼‰`);
      
      // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
      try {
        if (fs.existsSync(inputFile)) fs.unlinkSync(inputFile);
        if (fs.existsSync(outputFile)) fs.unlinkSync(outputFile);
      } catch (e) {
        // å¿½ç•¥æ¸…ç†é”™è¯¯
      }
      
      // è¿”å›åŸå§‹éŸ³é¢‘
      return audioBuffer;
    }
  }

  /**
   * è·å–BGMæ–‡ä»¶è·¯å¾„
   */
  private static getBgmFilePath(bgmFileName: string): string {
    const possiblePaths = [
      path.join(__dirname, '../config/bgm', bgmFileName),           // å¼€å‘ç¯å¢ƒ (src/)
      path.join(__dirname, '../../src/config/bgm', bgmFileName),    // ç¼–è¯‘å (dist/)
      path.join(process.cwd(), 'src/config/bgm', bgmFileName),      // ä»é¡¹ç›®æ ¹ç›®å½•
    ];

    for (const bgmPath of possiblePaths) {
      if (fs.existsSync(bgmPath)) {
        console.log(`âœ… æ‰¾åˆ°BGMæ–‡ä»¶: ${bgmPath}`);
        return bgmPath;
      }
    }

    throw new Error(`æœªæ‰¾åˆ°BGMæ–‡ä»¶: ${bgmFileName}`);
  }

  /**
   * æ·»åŠ BGMåˆ°éŸ³é¢‘ï¼ˆå‰å¥ç‹¬ç«‹ + æ··éŸ³æ·¡å…¥å¯¹è¯ + çº¯å¯¹è¯ + æ··éŸ³æ·¡å‡ºå¯¹è¯ + ç»“å°¾ç‹¬ç«‹ï¼‰
   * @param audioFile åŸå§‹éŸ³é¢‘æ–‡ä»¶è·¯å¾„
   * @param bgmFilePath BGMæ–‡ä»¶è·¯å¾„
   * @param introDuration å‰å¥ç‹¬ç«‹æ’­æ”¾æ—¶é•¿ï¼ˆç§’ï¼‰
   * @param outroDuration ç»“å°¾ç‹¬ç«‹æ’­æ”¾æ—¶é•¿ï¼ˆç§’ï¼‰
   * @param format éŸ³é¢‘æ ¼å¼
   * @param tempDir ä¸´æ—¶ç›®å½•
   * @returns æ·»åŠ BGMåçš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
   */
  private static async addBgmToAudio(
    audioFile: string,
    bgmFilePath: string,
    introDuration: number,
    outroDuration: number,
    format: 'mp3' | 'ogg_opus' | 'pcm' | 'wav',
    tempDir: string
  ): Promise<string> {
    // æ–°çš„æ·¡å…¥æ·¡å‡ºæ–¹æ¡ˆ
    const bgmFadeToMidDuration = 1; // BGMä»100%æ·¡å‡ºåˆ°60%çš„æ—¶é•¿
    const bgmFadeToZeroDuration = 8; // BGMä»60%ç»§ç»­æ·¡å‡ºåˆ°0%çš„æ—¶é•¿ï¼ˆåŒæ—¶å¯¹è¯å¼€å§‹ï¼‰
    const bgmMidVolume = 0.6; // BGMä¸­é—´éŸ³é‡ï¼ˆ60%ï¼‰
    const totalFadeOutDuration = bgmFadeToMidDuration + bgmFadeToZeroDuration; // æ€»æ·¡å‡ºæ—¶é•¿ 9ç§’
    
    // æ·¡å…¥ä½¿ç”¨ç›¸åŒçš„é€»è¾‘ï¼ˆä½†æ–¹å‘ç›¸åï¼‰
    const bgmFadeInFromZeroDuration = 10; // BGMä»0%æ·¡å…¥åˆ°60%ï¼ˆåŒæ—¶å¯¹è¯ç»“æŸï¼‰
    const bgmFadeInToFullDuration = 1; // BGMä»60%ç»§ç»­æ·¡å…¥åˆ°100%
    const totalFadeInDuration = bgmFadeInFromZeroDuration + bgmFadeInToFullDuration; // æ€»æ·¡å…¥æ—¶é•¿ 11ç§’

    // ç¡®ä¿æ—¶é•¿å‚æ•°æ˜¯æ•°å­—ç±»å‹ï¼ˆé˜²æ­¢å­—ç¬¦ä¸²ä¼ å…¥ï¼‰
    const introSec = Number(introDuration);
    const outroSec = Number(outroDuration);
    
    if (isNaN(introSec) || isNaN(outroSec)) {
      throw new Error(`æ— æ•ˆçš„BGMæ—¶é•¿å‚æ•°: intro=${introDuration}, outro=${outroDuration}`);
    }

    console.log(`ğŸ¼ æ·»åŠ BGMåˆ°éŸ³é¢‘ï¼ˆæ’­å®¢æ¨¡å¼ - æ–°ç‰ˆè‡ªç„¶è¿‡æ¸¡ï¼‰...`);
    console.log(`   å‰å¥BGMç‹¬ç«‹: ${introSec}ç§’ (BGM 100%)`);
    console.log(`   BGMæ·¡å‡ºç¬¬ä¸€é˜¶æ®µ: ${bgmFadeToMidDuration}ç§’ (BGM 100%â†’60%)`);
    console.log(`   BGMæ·¡å‡ºç¬¬äºŒé˜¶æ®µ + å¯¹è¯å¼€å§‹: ${bgmFadeToZeroDuration}ç§’ (BGM 60%â†’0% + å¯¹è¯æ·¡å…¥)`);
    console.log(`   ä¸­é—´çº¯å¯¹è¯: (å¯¹è¯100%ï¼Œæ— BGM)`);
    console.log(`   å¯¹è¯æ·¡å‡º + BGMæ·¡å…¥ç¬¬ä¸€é˜¶æ®µ: ${bgmFadeInFromZeroDuration}ç§’ (å¯¹è¯æ·¡å‡º + BGM 0%â†’60%)`);
    console.log(`   BGMæ·¡å…¥ç¬¬äºŒé˜¶æ®µ: ${bgmFadeInToFullDuration}ç§’ (BGM 60%â†’100%)`);
    console.log(`   ç»“å°¾BGMç‹¬ç«‹: ${outroSec}ç§’ (BGM 100%)`);

    // è·å–å¯¹è¯æ—¶é•¿
    const dialogueDuration = await this.getAudioDuration(audioFile);
    // æ€»æ—¶é•¿ = å‰å¥ + BGMç¬¬ä¸€é˜¶æ®µæ·¡å‡º + å¯¹è¯ï¼ˆå«BGMç¬¬äºŒé˜¶æ®µæ·¡å‡ºå’Œæ·¡å…¥ï¼‰ + BGMç¬¬äºŒé˜¶æ®µæ·¡å…¥ + ç»“å°¾
    const totalDuration = introSec + bgmFadeToMidDuration + dialogueDuration + bgmFadeInToFullDuration + outroSec;
    console.log(`   å¯¹è¯æ—¶é•¿: ${dialogueDuration.toFixed(2)}ç§’, æ€»æ—¶é•¿: ${totalDuration.toFixed(2)}ç§’`);

    // ä¸´æ—¶æ–‡ä»¶åˆ—è¡¨ï¼ˆç”¨äºæœ€åæ¸…ç†ï¼‰
    const tempFiles: string[] = [];
    
    try {
      // 1. è·å–åŸå§‹BGMçš„æ—¶é•¿
      const originalBgmDuration = await this.getAudioDuration(bgmFilePath);
      console.log(`ğŸ“ åŸå§‹BGMæ—¶é•¿: ${originalBgmDuration.toFixed(2)}ç§’`);
      
      // è®¡ç®—ç»“å°¾éœ€è¦çš„BGMæ—¶é•¿ï¼ˆç¬¬äºŒé˜¶æ®µæ·¡å…¥ + ç»“å°¾ç‹¬ç«‹ï¼‰
      const outroNeededDuration = bgmFadeInToFullDuration + outroSec;
      
      // è®¡ç®—ç»“å°¾BGMçš„èµ·å§‹ä½ç½®ï¼ˆä»BGMåé¢éƒ¨åˆ†æˆªå–ï¼Œä¿ç•™è‡ªç„¶ç»“å°¾ï¼‰
      let outroStartInOriginal = originalBgmDuration - outroNeededDuration;
      if (outroStartInOriginal < 0) {
        console.warn(`âš ï¸  BGMæ—¶é•¿ä¸è¶³ä»¥æä¾›å®Œæ•´ç»“å°¾ï¼Œå°†ä½¿ç”¨æ•´ä¸ªBGM: éœ€è¦${outroNeededDuration}ç§’ï¼Œå®é™…${originalBgmDuration}ç§’`);
        outroStartInOriginal = 0;
      }
      
      console.log(`ğŸµ BGMç»“å°¾ç­–ç•¥: ä½¿ç”¨åŸå§‹BGMçš„è‡ªç„¶ç»“å°¾ï¼ˆ${outroStartInOriginal.toFixed(2)}ç§’ â†’ ${originalBgmDuration.toFixed(2)}ç§’ï¼‰`);
      
      // 2. å‡†å¤‡ä¸­é—´éƒ¨åˆ†çš„BGMï¼ˆå¾ªç¯ï¼‰- ä¸åŒ…å«ç»“å°¾
      console.log(`ğŸ”„ å‡†å¤‡BGMéŸ³è½¨ï¼ˆå‰å¥+ä¸­é—´å¾ªç¯éƒ¨åˆ†ï¼‰...`);
      const middleDuration = totalDuration - outroNeededDuration;
      const loopedBgmFile = path.join(tempDir, `looped_bgm_${uuid.v4()}.${format}`);
      tempFiles.push(loopedBgmFile);
      
      await new Promise<void>((resolve, reject) => {
        ffmpeg(this.normalizePath(bgmFilePath))
          .inputOptions(['-stream_loop', '-1']) // æ— é™å¾ªç¯
          .duration(middleDuration)
          .audioCodec(this.getAudioCodec(format))
          .format(format)
          .outputOptions([
            '-max_muxing_queue_size', '4096',
            '-avoid_negative_ts', 'make_zero',
            '-fflags', '+genpts',
            '-q:a', '0'
          ])
          .save(this.normalizePath(loopedBgmFile))
          .on('end', () => {
            console.log(`âœ… BGMå¾ªç¯éƒ¨åˆ†ç”Ÿæˆå®Œæˆ: ${middleDuration.toFixed(2)}ç§’`);
            resolve();
          })
          .on('error', (err) => {
            console.error(`âŒ BGMå¾ªç¯é”™è¯¯: ${err.message}`);
            reject(err);
          });
      });

      // 3. ä¸ºå¯¹è¯å‰åæ·»åŠ é™éŸ³
      console.log(`ğŸ”‡ ä¸ºå¯¹è¯æ·»åŠ å‰åé™éŸ³...`);
      const paddedDialogueFile = path.join(tempDir, `padded_dialogue_${uuid.v4()}.${format}`);
      tempFiles.push(paddedDialogueFile);
      
      // ç”Ÿæˆå‰ç½®é™éŸ³ï¼ˆå‰å¥ + BGMç¬¬ä¸€é˜¶æ®µæ·¡å‡ºï¼‰
      const frontSilenceFile = await this.generateSilence(introSec + bgmFadeToMidDuration, 24000, format, tempDir);
      tempFiles.push(frontSilenceFile);
      
      // ç”Ÿæˆåç½®é™éŸ³ï¼ˆBGMç¬¬äºŒé˜¶æ®µæ·¡å…¥ + ç»“å°¾ï¼‰
      const backSilenceFile = await this.generateSilence(bgmFadeInToFullDuration + outroSec, 24000, format, tempDir);
      tempFiles.push(backSilenceFile);
      
      // æ‹¼æ¥ï¼šå‰é™éŸ³ + å¯¹è¯ + åé™éŸ³
      const concatListFile = path.join(tempDir, `dialogue_concat_${uuid.v4()}.txt`);
      tempFiles.push(concatListFile);
      
      fs.writeFileSync(concatListFile, [
        `file '${this.normalizePath(frontSilenceFile)}'`,
        `file '${this.normalizePath(audioFile)}'`,
        `file '${this.normalizePath(backSilenceFile)}'`
      ].join('\n'));
      
      await new Promise<void>((resolve, reject) => {
        ffmpeg()
          .input(this.normalizePath(concatListFile))
          .inputOptions(['-f concat', '-safe 0'])
          .audioCodec(this.getAudioCodec(format))
          .format(format)
          .outputOptions([
            '-max_muxing_queue_size', '4096',
            '-avoid_negative_ts', 'make_zero',
            '-fflags', '+genpts',
            '-q:a', '0'
          ])
          .save(this.normalizePath(paddedDialogueFile))
          .on('end', () => {
            console.log(`âœ… å¯¹è¯é™éŸ³å¡«å……å®Œæˆ`);
            resolve();
          })
          .on('error', (err) => {
            console.error(`âŒ å¯¹è¯æ‹¼æ¥é”™è¯¯: ${err.message}`);
            reject(err);
          });
      });

      // 4. åˆ†æ®µå¤„ç†BGMï¼ˆå‰å¥100% + ä¸¤é˜¶æ®µæ·¡å‡º + é™éŸ³ + ä¸¤é˜¶æ®µæ·¡å…¥ + è‡ªç„¶ç»“å°¾100%ï¼‰
      console.log(`ğŸšï¸ åˆ†æ®µå¤„ç†BGM...`);
      
      // è®¡ç®—å…³é”®æ—¶é—´ç‚¹
      const fadeToMidEnd = introSec + bgmFadeToMidDuration;  // BGMç¬¬ä¸€é˜¶æ®µæ·¡å‡ºç»“æŸï¼ˆåˆ°60%ï¼‰
      const fadeToZeroEnd = fadeToMidEnd + bgmFadeToZeroDuration;  // BGMç¬¬äºŒé˜¶æ®µæ·¡å‡ºç»“æŸï¼ˆåˆ°0%ï¼‰
      const dialogueStart = introSec + bgmFadeToMidDuration;  // å¯¹è¯å¼€å§‹æ—¶é—´ï¼ˆåœ¨BGMç¬¬äºŒé˜¶æ®µæ·¡å‡ºæœŸé—´ï¼‰
      const dialogueEnd = dialogueStart + dialogueDuration;  // å¯¹è¯ç»“æŸæ—¶é—´
      const fadeInFromZeroStart = dialogueEnd - bgmFadeInFromZeroDuration;  // BGMç¬¬ä¸€é˜¶æ®µæ·¡å…¥å¼€å§‹ï¼ˆä»0%ï¼‰
      const fadeInToFullStart = dialogueEnd;  // BGMç¬¬äºŒé˜¶æ®µæ·¡å…¥å¼€å§‹ï¼ˆä»60%åˆ°100%ï¼‰
      const fadeInToFullEnd = fadeInToFullStart + bgmFadeInToFullDuration;  // BGMç¬¬äºŒé˜¶æ®µæ·¡å…¥ç»“æŸ
      const silenceDuration = fadeInFromZeroStart - fadeToZeroEnd;  // ä¸­é—´é™éŸ³æ—¶é•¿
      
      console.log(`   BGMæ—¶é—´è½´:`);
      console.log(`   0-${introSec}s: å‰å¥ 100%`);
      console.log(`   ${introSec}-${fadeToMidEnd}s: ç¬¬ä¸€é˜¶æ®µæ·¡å‡º 100%â†’60% (${bgmFadeToMidDuration}ç§’)`);
      console.log(`   ${fadeToMidEnd}-${fadeToZeroEnd}s: ç¬¬äºŒé˜¶æ®µæ·¡å‡º 60%â†’0% (${bgmFadeToZeroDuration}ç§’)`);
      console.log(`   ${fadeToZeroEnd}-${fadeInFromZeroStart}s: é™éŸ³ ${silenceDuration.toFixed(1)}ç§’`);
      console.log(`   ${fadeInFromZeroStart}-${dialogueEnd}s: ç¬¬ä¸€é˜¶æ®µæ·¡å…¥ 0%â†’60% (${bgmFadeInFromZeroDuration}ç§’)`);
      console.log(`   ${fadeInToFullStart}-${fadeInToFullEnd}s: ç¬¬äºŒé˜¶æ®µæ·¡å…¥ 60%â†’100% (${bgmFadeInToFullDuration}ç§’)`);
      console.log(`   ${fadeInToFullEnd}-${totalDuration}s: ç»“å°¾ 100%`);
      console.log(`   å¯¹è¯æ—¶é—´è½´:`);
      console.log(`   ${dialogueStart}s å¯¹è¯å¼€å§‹ (BGMç¬¬äºŒé˜¶æ®µæ·¡å‡ºåŒæ—¶è¿›è¡Œ)`);
      console.log(`   ${dialogueEnd}s å¯¹è¯ç»“æŸ (BGMç¬¬äºŒé˜¶æ®µæ·¡å…¥åŒæ—¶å¼€å§‹)`);
      
      // 4.1 å‰å¥éƒ¨åˆ†ï¼ˆ100%éŸ³é‡ï¼‰
      const introBgmPart = path.join(tempDir, `bgm_intro_${uuid.v4()}.${format}`);
      tempFiles.push(introBgmPart);
      await new Promise<void>((resolve, reject) => {
        ffmpeg(this.normalizePath(loopedBgmFile))
          .setStartTime(0)
          .duration(introSec)
          .audioCodec('copy')
          .save(this.normalizePath(introBgmPart))
          .on('end', () => resolve())
          .on('error', (err) => reject(err));
      });
      
      // 4.2 ç¬¬ä¸€é˜¶æ®µæ·¡å‡ºï¼ˆ100% â†’ 60%ï¼‰
      // åˆ†ä¸¤æ­¥ï¼šå…ˆæå–å…¨éŸ³é‡ç‰‡æ®µï¼Œå†åº”ç”¨éŸ³é‡æ¸å˜
      const fadeToMidTempPart = path.join(tempDir, `bgm_temp_mid_${uuid.v4()}.${format}`);
      tempFiles.push(fadeToMidTempPart);
      
      // ç¬¬ä¸€æ­¥ï¼šæå–ç‰‡æ®µï¼ˆä¿æŒ100%éŸ³é‡ï¼‰
      await new Promise<void>((resolve, reject) => {
        ffmpeg(this.normalizePath(loopedBgmFile))
          .setStartTime(introSec)
          .duration(bgmFadeToMidDuration)
          .audioCodec('copy')
          .save(this.normalizePath(fadeToMidTempPart))
          .on('end', () => resolve())
          .on('error', (err) => reject(err));
      });
      
      // ç¬¬äºŒæ­¥ï¼šåº”ç”¨éŸ³é‡æ¸å˜ï¼ˆä»100%é™åˆ°60%ï¼‰
      const fadeToMidPart = path.join(tempDir, `bgm_fade_to_mid_${uuid.v4()}.${format}`);
      tempFiles.push(fadeToMidPart);
      await new Promise<void>((resolve, reject) => {
        // è®¡ç®—éŸ³é‡å‡å°‘é‡ï¼šä»1.0åˆ°0.6ï¼Œå‡å°‘0.4
        const volumeDecrease = 1.0 - bgmMidVolume;
        ffmpeg(this.normalizePath(fadeToMidTempPart))
          .audioFilters(`volume=volume='1-${volumeDecrease}*t/${bgmFadeToMidDuration}':eval=frame`)
          .audioCodec(this.getAudioCodec(format))
          .outputOptions(['-q:a', '0'])
          .save(this.normalizePath(fadeToMidPart))
          .on('end', () => resolve())
          .on('error', (err) => reject(err));
      });
      
      // 4.3 ç¬¬äºŒé˜¶æ®µæ·¡å‡ºï¼ˆ60% â†’ 0%ï¼‰
      const fadeToZeroTempPart = path.join(tempDir, `bgm_temp_zero_${uuid.v4()}.${format}`);
      tempFiles.push(fadeToZeroTempPart);
      
      // ç¬¬ä¸€æ­¥ï¼šæå–ç‰‡æ®µ
      await new Promise<void>((resolve, reject) => {
        ffmpeg(this.normalizePath(loopedBgmFile))
          .setStartTime(fadeToMidEnd)
          .duration(bgmFadeToZeroDuration)
          .audioCodec('copy')
          .save(this.normalizePath(fadeToZeroTempPart))
          .on('end', () => resolve())
          .on('error', (err) => reject(err));
      });
      
      // ç¬¬äºŒæ­¥ï¼šå…ˆè®¾ç½®60%éŸ³é‡ï¼Œç„¶åå®Œå…¨æ·¡å‡ºåˆ°0%
      const fadeToZeroPart = path.join(tempDir, `bgm_fade_to_zero_${uuid.v4()}.${format}`);
      tempFiles.push(fadeToZeroPart);
      await new Promise<void>((resolve, reject) => {
        ffmpeg(this.normalizePath(fadeToZeroTempPart))
          .audioFilters([
            `volume=${bgmMidVolume}`,
            `afade=t=out:st=0:d=${bgmFadeToZeroDuration}`
          ])
          .audioCodec(this.getAudioCodec(format))
          .outputOptions(['-q:a', '0'])
          .save(this.normalizePath(fadeToZeroPart))
          .on('end', () => resolve())
          .on('error', (err) => reject(err));
      });
      
      // 4.4 é™éŸ³éƒ¨åˆ†
      const silencePart = await this.generateSilence(silenceDuration, 24000, format, tempDir);
      tempFiles.push(silencePart);
      
      // 4.5 ç¬¬ä¸€é˜¶æ®µæ·¡å…¥ï¼ˆ0% â†’ 60%ï¼‰
      const fadeFromZeroTempPart = path.join(tempDir, `bgm_temp_from_zero_${uuid.v4()}.${format}`);
      tempFiles.push(fadeFromZeroTempPart);
      
      // ç¬¬ä¸€æ­¥ï¼šæå–ç‰‡æ®µ
      await new Promise<void>((resolve, reject) => {
        ffmpeg(this.normalizePath(loopedBgmFile))
          .setStartTime(fadeInFromZeroStart)
          .duration(bgmFadeInFromZeroDuration)
          .audioCodec('copy')
          .save(this.normalizePath(fadeFromZeroTempPart))
          .on('end', () => resolve())
          .on('error', (err) => reject(err));
      });
      
      // ç¬¬äºŒæ­¥ï¼šå…ˆæ·¡å…¥åˆ°100%ï¼Œç„¶åé™åˆ°60%éŸ³é‡
      const fadeFromZeroPart = path.join(tempDir, `bgm_fade_from_zero_${uuid.v4()}.${format}`);
      tempFiles.push(fadeFromZeroPart);
      await new Promise<void>((resolve, reject) => {
        ffmpeg(this.normalizePath(fadeFromZeroTempPart))
          .audioFilters([
            `afade=t=in:st=0:d=${bgmFadeInFromZeroDuration}`,
            `volume=${bgmMidVolume}`
          ])
          .audioCodec(this.getAudioCodec(format))
          .outputOptions(['-q:a', '0'])
          .save(this.normalizePath(fadeFromZeroPart))
          .on('end', () => resolve())
          .on('error', (err) => reject(err));
      });
      
      // 4.6 ç¬¬äºŒé˜¶æ®µæ·¡å…¥ï¼ˆ60% â†’ 100%ï¼‰- ä»åŸå§‹BGMæˆªå–
      console.log(`ğŸµ æå–BGMè‡ªç„¶ç»“å°¾ï¼ˆç¬¬äºŒé˜¶æ®µæ·¡å…¥éƒ¨åˆ†ï¼‰...`);
      const fadeToFullTempPart = path.join(tempDir, `bgm_temp_to_full_${uuid.v4()}.${format}`);
      tempFiles.push(fadeToFullTempPart);
      
      // ç¬¬ä¸€æ­¥ï¼šä»åŸå§‹BGMæå–ç‰‡æ®µï¼ˆä¿ç•™è‡ªç„¶éŸ³è´¨ï¼‰
      await new Promise<void>((resolve, reject) => {
        ffmpeg(this.normalizePath(bgmFilePath))
          .setStartTime(outroStartInOriginal)
          .duration(bgmFadeInToFullDuration)
          .audioCodec('copy')
          .save(this.normalizePath(fadeToFullTempPart))
          .on('end', () => resolve())
          .on('error', (err) => reject(err));
      });
      
      // ç¬¬äºŒæ­¥ï¼šåº”ç”¨éŸ³é‡æ¸å˜ï¼ˆä»60%å‡åˆ°100%ï¼‰
      const fadeToFullPart = path.join(tempDir, `bgm_fade_to_full_${uuid.v4()}.${format}`);
      tempFiles.push(fadeToFullPart);
      await new Promise<void>((resolve, reject) => {
        // è®¡ç®—éŸ³é‡å¢åŠ é‡ï¼šä»0.6åˆ°1.0ï¼Œå¢åŠ 0.4
        const volumeIncrease = 1.0 - bgmMidVolume;
        ffmpeg(this.normalizePath(fadeToFullTempPart))
          .audioFilters(`volume=volume='${bgmMidVolume}+${volumeIncrease}*t/${bgmFadeInToFullDuration}':eval=frame`)
          .audioCodec(this.getAudioCodec(format))
          .outputOptions(['-q:a', '0'])
          .save(this.normalizePath(fadeToFullPart))
          .on('end', () => resolve())
          .on('error', (err) => reject(err));
      });
      
      // 4.7 ç»“å°¾éƒ¨åˆ†ï¼ˆ100%éŸ³é‡ï¼‰- ä»åŸå§‹BGMæˆªå–è‡ªç„¶ç»“å°¾
      console.log(`ğŸµ æå–BGMè‡ªç„¶ç»“å°¾ï¼ˆ100%éŸ³é‡éƒ¨åˆ†ï¼‰...`);
      const outroBgmPart = path.join(tempDir, `bgm_outro_${uuid.v4()}.${format}`);
      tempFiles.push(outroBgmPart);
      const outroFullStart = outroStartInOriginal + bgmFadeInToFullDuration; // ç¬¬äºŒé˜¶æ®µæ·¡å…¥ä¹‹å
      const outroFullDuration = originalBgmDuration - outroFullStart; // ä»è¿™é‡Œåˆ°BGMçœŸå®ç»“æŸ
      
      console.log(`   ä»åŸå§‹BGM ${outroFullStart.toFixed(2)}ç§’ æå–åˆ° ${originalBgmDuration.toFixed(2)}ç§’ï¼ˆæ—¶é•¿: ${outroFullDuration.toFixed(2)}ç§’ï¼‰`);
      
      await new Promise<void>((resolve, reject) => {
        ffmpeg(this.normalizePath(bgmFilePath))
          .setStartTime(outroFullStart)
          .duration(outroFullDuration)
          .audioCodec('copy')
          .save(this.normalizePath(outroBgmPart))
          .on('end', () => {
            console.log(`âœ… BGMè‡ªç„¶ç»“å°¾æå–å®Œæˆ`);
            resolve();
          })
          .on('error', (err) => reject(err));
      });
      
      // 4.8 æ‹¼æ¥æ‰€æœ‰BGMéƒ¨åˆ†
      console.log(`ğŸ”— æ‹¼æ¥BGMå„éƒ¨åˆ†...`);
      const processedBgmFile = path.join(tempDir, `processed_bgm_${uuid.v4()}.${format}`);
      tempFiles.push(processedBgmFile);
      
      const bgmConcatList = path.join(tempDir, `bgm_concat_${uuid.v4()}.txt`);
      tempFiles.push(bgmConcatList);
      
      fs.writeFileSync(bgmConcatList, [
        `file '${this.normalizePath(introBgmPart)}'`,
        `file '${this.normalizePath(fadeToMidPart)}'`,
        `file '${this.normalizePath(fadeToZeroPart)}'`,
        `file '${this.normalizePath(silencePart)}'`,
        `file '${this.normalizePath(fadeFromZeroPart)}'`,
        `file '${this.normalizePath(fadeToFullPart)}'`,
        `file '${this.normalizePath(outroBgmPart)}'`
      ].join('\n'));
      
      await new Promise<void>((resolve, reject) => {
        ffmpeg()
          .input(this.normalizePath(bgmConcatList))
          .inputOptions(['-f concat', '-safe 0'])
          .audioCodec(this.getAudioCodec(format))
          .format(format)
          .outputOptions([
            '-max_muxing_queue_size', '4096',
            '-avoid_negative_ts', 'make_zero',
            '-fflags', '+genpts',
            '-q:a', '0'
          ])
          .save(this.normalizePath(processedBgmFile))
          .on('start', (cmdLine) => {
            console.log(`   æ‹¼æ¥å‘½ä»¤: ${cmdLine.substring(0, 100)}...`);
          })
          .on('end', () => {
            console.log(`âœ… BGMå¤„ç†å®Œæˆï¼ˆå‰å¥â†’æ·¡å‡º60%â†’æ·¡å‡º0%â†’é™éŸ³â†’æ·¡å…¥60%â†’æ·¡å…¥100%â†’è‡ªç„¶ç»“å°¾ï¼‰`);
            resolve();
          })
          .on('error', (err) => {
            console.error(`âŒ BGMæ‹¼æ¥é”™è¯¯: ${err.message}`);
            reject(err);
          });
      });

      // 5. æ··éŸ³ï¼šBGM + å¯¹è¯ï¼ˆè°ƒæ•´éŸ³é‡å¹³è¡¡ï¼Œç¡®ä¿äººå£°æ¸…æ™°ï¼‰
      console.log(`ğŸµ æ··éŸ³BGMå’Œå¯¹è¯...`);
      
      // ä»é…ç½®æ–‡ä»¶è¯»å–æ··éŸ³éŸ³é‡é…ç½®
      const podcastConfigPath = path.join(__dirname, '../config/podcast.config.json');
      let bgmVolume = 0.25;  // é»˜è®¤BGMéŸ³é‡25%
      let voiceVolume = 1.0; // é»˜è®¤äººå£°éŸ³é‡100%
      
      try {
        const podcastConfig = JSON.parse(fs.readFileSync(podcastConfigPath, 'utf-8'));
        if (podcastConfig.audio_mixing) {
          bgmVolume = podcastConfig.audio_mixing.bgm_volume || 0.25;
          voiceVolume = podcastConfig.audio_mixing.voice_volume || 1.0;
        }
      } catch (e) {
        console.warn(`âš ï¸  æ— æ³•è¯»å–æ··éŸ³é…ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼`);
      }
      
      console.log(`   éŸ³é‡å¹³è¡¡: äººå£° ${(voiceVolume * 100).toFixed(0)}% | BGM ${(bgmVolume * 100).toFixed(0)}%ï¼ˆèƒŒæ™¯éŸ³ä¹æŸ”å’Œï¼‰`);
      const finalOutput = path.join(tempDir, `with_bgm_final_${uuid.v4()}.${format}`);
      
      await new Promise<void>((resolve, reject) => {
        const cmd = ffmpeg()
          .input(this.normalizePath(processedBgmFile))
          .input(this.normalizePath(paddedDialogueFile))
          .complexFilter([
            // å…ˆè®¾ç½®å„è‡ªéŸ³é‡ï¼Œç„¶åæ··éŸ³
            // BGMä½œä¸ºèƒŒæ™¯ï¼Œäººå£°æ¸…æ™°å¯é—»
            `[0:a]volume=${bgmVolume}[bgm]`,
            `[1:a]volume=${voiceVolume}[voice]`,
            '[bgm][voice]amix=inputs=2:duration=longest:dropout_transition=0[outa]'
          ])
          .outputOptions(['-map', '[outa]'])
          .audioCodec(this.getAudioCodec(format))
          .format(format);
        
        // æ·»åŠ è´¨é‡å‚æ•°
        const qualityOptions = this.getQualityOptions(format);
        if (qualityOptions.length > 0) {
          cmd.outputOptions(qualityOptions);
        }
        
        // ä¼˜åŒ–è¾“å‡ºé€‰é¡¹ï¼Œé¿å…"Result too large"é”™è¯¯
        cmd.outputOptions([
          '-max_muxing_queue_size', '4096',
          '-avoid_negative_ts', 'make_zero',
          '-fflags', '+genpts'
        ]);
        
        cmd.save(this.normalizePath(finalOutput))
          .on('start', (commandLine) => {
            console.log(`   æ‰§è¡Œå‘½ä»¤: ${commandLine.substring(0, 200)}...`);
          })
          .on('end', () => {
            console.log(`âœ… æ··éŸ³å®Œæˆ`);
            resolve();
          })
          .on('error', (err) => {
            console.error(`âŒ æ··éŸ³é”™è¯¯: ${err.message}`);
            reject(err);
          });
      });

      // 6. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
      console.log(`ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶...`);
      tempFiles.forEach(file => {
        if (fs.existsSync(file)) {
          try {
            fs.unlinkSync(file);
          } catch (e) {
            console.warn(`âš ï¸  åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: ${file}`);
          }
        }
      });

      console.log(`âœ… BGMå¤„ç†å®Œæˆï¼ˆå‰å¥ â†’ æ·¡å‡º60% â†’ æ·¡å‡º0%+å¯¹è¯ â†’ çº¯å¯¹è¯ â†’ å¯¹è¯+æ·¡å…¥60% â†’ æ·¡å…¥100% â†’ è‡ªç„¶ç»“å°¾ ğŸµï¼‰`);
      return finalOutput;
      
    } catch (error: any) {
      // å‡ºé”™æ—¶æ¸…ç†ä¸´æ—¶æ–‡ä»¶
      console.error(`âŒ BGMå¤„ç†å¤±è´¥: ${error.message}`);
      tempFiles.forEach(file => {
        if (fs.existsSync(file)) {
          try {
            fs.unlinkSync(file);
          } catch (e) {}
        }
      });
      throw new Error(`æ··éŸ³å¤±è´¥: ${error.message}`);
    }
  }

  /**
   * è·å–éŸ³é¢‘æ–‡ä»¶æ—¶é•¿ï¼ˆç§’ï¼‰
   */
  private static async getAudioDuration(audioFile: string): Promise<number> {
    return new Promise((resolve, reject) => {
      ffmpeg.ffprobe(this.normalizePath(audioFile), (err, metadata) => {
        if (err) {
          reject(err);
        } else {
          const duration = metadata.format.duration || 0;
          resolve(duration);
        }
      });
    });
  }

  /**
   * è·å–éŸ³é¢‘Bufferçš„æ—¶é•¿ï¼ˆç§’ï¼‰
   * é€šè¿‡å†™å…¥ä¸´æ—¶æ–‡ä»¶ç„¶åä½¿ç”¨ ffprobe è·å–æ—¶é•¿
   */
  static async getAudioBufferDuration(
    audioBuffer: Buffer,
    format: 'mp3' | 'ogg_opus' | 'pcm' | 'wav'
  ): Promise<number> {
    const tempDir = path.join(process.cwd(), 'temp');
    if (!fs.existsSync(tempDir)) {
      fs.mkdirSync(tempDir, { recursive: true });
    }

    const tempFile = path.join(tempDir, `temp_duration_${uuid.v4()}.${format}`);
    
    try {
      // å†™å…¥ä¸´æ—¶æ–‡ä»¶
      fs.writeFileSync(tempFile, audioBuffer);
      
      // è·å–æ—¶é•¿
      const duration = await this.getAudioDuration(tempFile);
      
      return duration;
    } finally {
      // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
      if (fs.existsSync(tempFile)) {
        fs.unlinkSync(tempFile);
      }
    }
  }

  /**
   * ç”Ÿæˆå®Œæ•´æ’­å®¢éŸ³é¢‘
   */
  static async generatePodcastAudio(
    dialogue: PodcastDialogue[],
    taskId?: number,
    options?: {
      format?: 'mp3' | 'ogg_opus' | 'pcm' | 'wav';
      sampleRate?: number;
      speechRate?: number;
      onProgress?: (current: number, total: number) => void;
      bgmFile?: string;
      introMusicDuration?: number;
      outroMusicDuration?: number;
    }
  ): Promise<Buffer> {
    console.log(`ğŸ¬ ç”Ÿæˆæ’­å®¢éŸ³é¢‘ - ${dialogue.length}æ®µå¯¹è¯`);

    const format = options?.format || 'mp3';

    // æ­¥éª¤1: æ‰¹é‡åˆæˆæ‰€æœ‰å¯¹è¯
    const segments = await this.synthesizeDialogue(dialogue, taskId, options);

    // æ­¥éª¤2: åˆå¹¶éŸ³é¢‘ç‰‡æ®µï¼ˆä¸è¿›è¡ŒéŸ³é‡æ ‡å‡†åŒ–ï¼‰
    let audioBuffer = await this.mergeAudioSegments(segments, dialogue, format);

    // æ­¥éª¤3: å¦‚æœæœ‰BGMé…ç½®ï¼Œæ·»åŠ BGM
    if (options?.bgmFile && options?.introMusicDuration && options?.outroMusicDuration) {
      console.log(`ğŸµ æ·»åŠ BGM: ${options.bgmFile}`);
      
      const normConfig = this.loadNormalizationConfig();
      const tempDir = path.join(process.cwd(), normConfig.processing.tempDir);
      
      if (!fs.existsSync(tempDir)) {
        fs.mkdirSync(tempDir, { recursive: true });
      }
      
      // å°†å¯¹è¯éŸ³é¢‘å†™å…¥ä¸´æ—¶æ–‡ä»¶
      const dialogueFile = path.join(tempDir, `dialogue_${uuid.v4()}.${format}`);
      fs.writeFileSync(dialogueFile, audioBuffer);

      try {
        // è·å–BGMæ–‡ä»¶è·¯å¾„
        const bgmFilePath = this.getBgmFilePath(options.bgmFile);

        // æ·»åŠ BGM
        const withBgmFile = await this.addBgmToAudio(
          dialogueFile,
          bgmFilePath,
          options.introMusicDuration,
          options.outroMusicDuration,
          format,
          tempDir
        );

        // è¯»å–æ·»åŠ BGMåçš„éŸ³é¢‘
        audioBuffer = fs.readFileSync(withBgmFile);

        // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        [dialogueFile, withBgmFile].forEach(file => {
          if (fs.existsSync(file)) {
            fs.unlinkSync(file);
          }
        });

        console.log(`âœ… BGMæ·»åŠ å®Œæˆ`);

      } catch (error: any) {
        console.error(`âŒ æ·»åŠ BGMå¤±è´¥: ${error.message}`);
        console.warn(`âš ï¸  é™çº§ä¸ºæ— BGMç‰ˆæœ¬`);
        
        // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if (fs.existsSync(dialogueFile)) {
          fs.unlinkSync(dialogueFile);
        }
        
        // ç»§ç»­ä½¿ç”¨æ— BGMçš„éŸ³é¢‘
      }
    }

    // æ­¥éª¤4: æœ€åå¯¹æ•´ä½“éŸ³é¢‘è¿›è¡ŒéŸ³é‡æ ‡å‡†åŒ–ï¼ˆåœ¨æ‰€æœ‰å†…å®¹å¤„ç†å®Œæˆåï¼‰
    console.log(`\nğŸ“Š æœ€ç»ˆå¤„ç†é˜¶æ®µ...`);
    const finalAudio = await this.normalizeAudioFinal(audioBuffer, format);

    console.log(`ğŸ‰ æ’­å®¢éŸ³é¢‘ç”Ÿæˆå®Œæˆ!`);
    return finalAudio;
  }

  /**
   * å»¶è¿Ÿå‡½æ•°
   */
  private static delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  /**
   * éªŒè¯é…ç½®
   */
  static validateConfig(): void {
    if (!this.APP_ID) {
      throw new Error('TTS_APP_ID æœªé…ç½®');
    }
    if (!this.ACCESS_TOKEN) {
      throw new Error('TTS_ACCESS_TOKEN æœªé…ç½®');
    }
    console.log('âœ… TTS é…ç½®éªŒè¯é€šè¿‡');
  }
}

